\chapter{Foreground Subtraction}
\label{cha:FR}

Foreground subtraction remains an open question in the field of RM radio astronomy. Due to the inherent magnetisation of the Galactic halo and the ISM, as discussed in sections [SECREF] and [SECREF], there are significant contributions to observed RMs from the Galactic foreground across the entire sky. To correctly determine the magnetic field surrounding objects of interest, one must first remove this source of systematic error.


A prime example of the consequences of not correctly accounting for foreground RM contributions is the paper by [SOURCE], which attempted to estimate the magnetic field strength surrounding HVCs in the Leading Arm. However, as from [SOURCE], this result is possibly erroneous due to the obstruction of the nearby Antila supernova remnant region. While the analysis of multiple HVCs is more likely to prevent these errors from compounding to invalidate the conclusions of the report, it is still useful to account for these contributions as much as possible.

\section{Interpolation}
\label{sec:intp}

All previous work on magnetic field analysis of HVCs involve the use of interpolation [SOURCE]. Interpolations are very beneficial due to its ability to convert a discrete distribution of RM grid points into a continuous distribution of the RM sky. Interpolations also benefit from a 'smoothing' effect; that interpolated maps can smooth out small-scale imperfections in the RM grid that may not correspond to actual foreground objects [SOURCE]. This smoothing can occur because of the interpolation algorithm itself, or the lack of RM grid density to resolve objects on a particular scale.


The primary issue with interpolation is that they are too effective a technique at reconstructing the RM foreground. Despite the smoothing effects that they can provide, there is no way one can generally confirm that the RM sky has not included objects of interest as well; in other words, an interpolated RM sky could contain the profiles of objects of interest. This has the effect of making interpolated maps sourced from high-density RM grids redundant, as the original intention of interpolation is to subtract out foreground contributors to RMs – not the objects of interest themselves.


Thus, with the increased RM grid density afforded by the POSSUM survey, and future SKA-era projects, it is of high importance that discussions on how to account for these issues can be solved.

\section{Annulus Subtraction}
\label{sec:annulus}

The immediate alternative is annulus subtraction. This is a method employed across all fields of astronomy, including radio astronomy, being most applicable to single-object analysis. The method generally involves selecting a series of RM sampling points surrounding any given central RM grid point, averaging the selected RMs, and subtracting the average from the central RM grid point.

There are two sub-methods to consider when performing annulus subtraction: fixed-size annulus subtraction and fixed-sampling annulus subtraction. Fixed-size annulus subtraction involves defining an annulus with a constant inner and outer radius and averaging the RMs exclusively within this radial range. Fixed-sampling annulus subtraction involves defining an inner radius and then selecting a fixed amount of RM grid points that are closest to the central point, but still outside the inner radius. Assuming a constant grid density everywhere in the field, a relationship between the two methods can be quantified, in the following equation:


[EQ]


Where [UNIT] is the RM grid density, r is the inner radius of the annulus, R is the outer radius of the annulus (which is directly fixed under the fixed-size regime), and N is the number of RM grid points used (which is directly fixed under the fixed-sampling regime). This means that under a constant RM grid density, these two methods should be approximately equivalent.


There are benefits to both methods. On one hand, fixed-size methods can be described mathematically as convolutions, making them linear. However, they can run into measurement and calculation errors when there is a low amount of RM grid points surrounding the central RM. On the other hand, fixed-sampling methods guarantee a consistent uncertainty and the existence of an average. However, this method is both non-linear and prone to including RM grid points very far away from the central point.


The primary issue with annulus subtraction is determining the size of the annulus, or the amount of RM sampling points to select i.e. what counts as the “foreground”. This issue is what leads to many of the above-mentioned errors in both methods. The logical response is either to select a large annulus that completely removes the objects' RM contributions (in the case of HVCs this would correspond to an annulus of 1-[NUM] degrees in radius), or to select a small radius with numerous RM points to capture the foreground contributions both overlapping the object and isolated in the field. Both methods will be analysed in this paper, with the former being discussed in section [SECREF] and the latter being shown in figure [FIG] [FOOTNOTE]. The specific choice of parameters in the latter method being an inner radius of 0.4” and a sample size of 50 grid points – corresponding to an outer radius of approx. [NUM].

\section{Fast Fourier Transforms (FFTs)}
\label{sec:ffts}

Many of the methods for foreground subtraction beyond interpolation appear to have a common intersection point in the form of image-based signal processing. Thus, the introduction of Fourier Transforms (FTs) may be a very useful direction for analysis. The benefit of FTs is their linearity, which has several benefits including: the trivialisation uncertainty calculations (quantified in equation [EQREF]); the linear combination of several kernel techniques; signal processing in separate orthogonal dimensions; and consistent scaling relationships. FTs also can utilise both convolutional blurring and bandpassing as separately, with convolutions already being discussed with annulus subtractions.


FFTs extend the benefits of FTs by providing a fast algorithm of [NUM] complexity and allowing FTs to be performed over discrete sets of data [SOURCE]. This allows for the analysis of high-definition pixellated images, which is not unlike the standard format and use-case of a FITS file, especially when using a cartesian projection of the sky. Thus, by applying 2-dimensional FFTs to provided interpolated RM sky images, it is possible to solve the problem introduced by interpolated high-density RM grids.

\subsection{Non-Uniform Fast Fourier Transforms (NUFFTs)}
\label{ssec:nuffts}

FFTs can further be extended to the analysis of non-uniform data sets. Standard FFTs rely on the assumption that the grid of sampling points is uniform, and resultantly output uniform-density frequency distributions. NUFFTs do not require the assumption of uniformity, nor do they need to output uniform-density frequency distributions [SOURCE]. This means that instead of relying on interpolations at all, FTs can be applied directly to the RM grid itself. The primary sources for NUFFTs used in this paper are [SOURCE], with heavy reliance on the python module [CODE].


There are three types of NUFFT: Forward, Adjoint, and “True” [FOOTNOTE]. The forward and adjoint types are inverses of each other – forward NUFFTs take a uniform image and a set of sampling points and return a non-uniform frequency distribution and adjoint NUFFTs reverses that process. True NUFFTs take a non-uniform distribution and output a non-uniform frequency distribution. True NUFFTs are not generally useful for the purposes of this report.


Applying a forward and then an adjoint NUFFT to a set of RM grid sampling points should perform the same task as creating an interpolation. From there, the intermediary step of a bandpass or kernel can be applied to the frequency distribution to produce an interpolation with objects of a particular scale removed from the field.


The important first step in determining if this method is useful is to attempt creating an interpolation. First, an image was selected, specifically a grayscale and cropped image of the Cosmic Microwave Background (CMB) from the Planck mission (see appendix [SECREF] for more). This was chosen as the test image due to the CMB being able to replicate a noisy and 'blobby' structure, the CMB has also been analysed using FFTs for unrelated cosmological purposes.


Then, a random set of sampling points were selected and treated as the 'mock RMs', with the colour of the background corresponding to the intensity of the RM at that point. The image and the sampling points were then given to the [CODE] module and transformed in and out of the frequency domain. Figure [FIG] represents the outcomes of this analysis, performed on a sample of simulated RM grids with size [NUM]. Ignoring the grid-like structure in the recreated image (a consequence of the random point generation algorithm), even with a very high sampling point density or large field, the image is still very low-quality.


This does not disqualify the NUFFT as an analysis technique. Instead, it means that this technique can only work on a very large continuously connected RM set i.e. a complete or partially complete RM grid map of the sky. However, due to the lack of POSSUM data in its early stages, this is a method that must be investigated in the future.

\subsection{Bandpass Filtering}
\label{ssec:bandpass}

A simpler method is to directly alter the interpolation itself using normal FFTs. First, a 2-D FFT was applied to the Hutschenreuter map. A crosshatch-shaped bandpass was created as seen in figure [FIG]. This crosshatch imitates a bandpass commonly applied to 1-dimensional signals, where objects of a particular angular size are eliminated by removing all frequencies corresponding to that angular size in the k-space. The equation below quantifies the relationship between frequency and angular size:


[EQ]


Where [UNIT] is the spatial frequency, [UNIT] is the angular size of the HVC, and R is the pixel resolution of the axis (measured in pixels per degree). Assuming all interpolation images exist in a 2:1 cartesian space, due to the range of galactic latitude and longitude, the value of R is constant across the two axes.


The crosshatch is shaped such that, when multiplied by the original k-space, objects of a particular size are either eliminated or reduced in prevalence. This method also guarantees the linearity of the crosshatch 'function'. After this, the inverse FFT is applied to give a resulting interpolation, seen in figure [FIG].


However, bandpassing introduces ripples into the interpolation. This effect is expected but undesirable. There are two methods to remove this: either to apply the crosshatch at a certain 'opacity' i.e. the crosshatch is not eliminating all the k-space in its region, but instead is reducing those frequencies by a percentage; or using a more complex window than a Top Hat, such as a Tukey window or Gaussian window. The effects of the former are seen in figure [FIG]. The latter was not investigated due to time constraints.


When applying FTs to any interpolated image, it is important to maintain the corresponding uncertainty map's accuracy. This is where one can take advantage of linearity. The following formula below determines how uncertainties can be calculated:


[EQ]


Where [UNIT] is the bandpass function, [UNIT] is the uncertainty image, and [UNIT] is the FT.

\subsection{Kernel Filtering}
\label{ssec:kernel}

The same techniques from above can be applied to convolutions, where the aim is to convolve the interpolation with a defined kernel. Two-dimensional convolutions have a time complexity of [NUM], depending on the kernel size k, whereas the FFT has a complexity [NUM]. By performing a FFT on both the kernel and the interpolation separately, then multiplying the two k-spaces together, and applying an inverse FFT, the result is a faster application of a convolution with a kernel. This was the chosen method to demonstrate the large fixed-size annulus subtraction method. Figure [FIG] displays the results of this method.


The main problem, as apparent from this method, is that the annulus kernel acts as an edge detection algorithm [SOURCE]. This causes defects at higher absolute galactic latitudes. Another problem is that this subtraction method is being applied to the interpolation, instead of the actual RM grid. This secondary issue can be solved by relying on the NUFFT of a larger RM grid. As it stands, this method appears to be incompatible with the goals of foreground removal.

\section{Characterising the RM data}
\label{sec:charm}

As seen from figures [FIG] and [FIG], there are several ways in which the RM grid can have 'bad data' – most notably in a lack of signal-to-noise and the inherent scatter when observing near the Galactic midplane. Thus, the final step of this chapter is to both characterise the RM sample set and to compare the methods against each other.


Figure [FIG] represents a simple residual histogram comparison between all the methods discussed in this chapter. The desired result is seen in the residuals between the interpolated or crosshatch-bandpassed RMs and the actual RMs - appearing as a normal distribution centred at zero.  This is opposed to the two annulus methods, which do not appear to interact with the RM grid in a desirable manner.


Figure [FIG] demonstrates the similarities between the crosshatch-bandpass and straight interpolation, with them being related to each other in a linear manner, specifically with a gradient of approximately unity. This is ideal, as it means that the crosshatch-bandpass method is not deviating significantly from the interpolation, only altering it subtly. The figure also demonstrates how scattered the RMs become near the galactic latitude, hence it being plotted for colour to delineate between RMs near and far away from the midplane.


Figure [FIG] is the same, but instead comparing with the annulus-convolved method (a.k.a. the fixed-sampling annulus method). There is a somewhat linear relationship between the actual RMs and the annulus-convolved RMs, ignoring the heavy scatter closer to the midplane. This gives credibility to this method, and the choice of having a small-sized annulus.


Lastly, figure [FIG] compares the two annulus methods together. The annulus-bandpass method (a.k.a. the fixed-size annulus method). From the bottom two graphs, the annulus bandpass overcorrects near the Galactic midplane, sending most RMs to near-zero. Despite this, RMs at higher galactic latitudes 'blow up'. This implies that the annulus-bandpass method is only viable for analysing objects close to the Galactic midplane. 

\section{Other Methods}
\label{sec:other_methods}

There are other methods for foreground removal that, while researched, were not considered viable options or of enough importance to numerically analyse in this report. However, they may still offer useful methods for future researchers. The first is median filtering, which is like previously discussed convolutional blurring methods. [SOURCE] provides a description of a fast median filtering algorithm for two-dimensional images. [SOURCE] is also a reference describing the potential benefits of median filtering, including a more robust removal of noise due to the statistical properties of the median, and the preservation of edges. It was disregarded in this report due to its inherent non-linearity, and the debatable nature of whether this disadvantage is worth the advantages it can bring. Linear decomposition of line-of-sight RMs are also possible, attempted in [SOURCE]. However, it is also quite mathematically complex and may not be conducive to a generalised algorithm, hence the lack of focus on this technique in this report.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
